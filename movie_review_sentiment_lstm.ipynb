{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw1_implementation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"lffFsqA8BbFV","executionInfo":{"status":"ok","timestamp":1644286042485,"user_tz":480,"elapsed":1800,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"outputs":[],"source":["import torch\n","from torchtext.legacy import data\n","\n","SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy',\n","                  tokenizer_language = 'en_core_web_sm')\n","LABEL = data.LabelField(dtype = torch.float)"]},{"cell_type":"code","source":["from torchtext.legacy import datasets\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n","print(f'Number of training examples: {len(train_data)}')\n","print(f'Number of testing examples: {len(test_data)}')\n","print(vars(train_data.examples[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IatXWViqB3Pi","executionInfo":{"status":"ok","timestamp":1644286150754,"user_tz":480,"elapsed":108278,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}},"outputId":"aa074292-3288-4531-a07d-c81e3ba7d6ee"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training examples: 25000\n","Number of testing examples: 25000\n","{'text': ['This', 'was', 'a', 'pretty', 'good', 'movie', ',', 'I', 'liked', 'it', '.', 'I', 'thought', 'it', 'was', 'a', 'pretty', 'accurate', 'look', 'at', 'bulimia', 'and', 'how', 'it', \"'s\", 'not', 'about', 'dieting', ',', 'it', \"'s\", 'about', 'having', 'a', 'pain', 'so', 'deep', 'that', 'they', 'have', 'to', 'find', 'a', 'way', 'to', 'deal', 'with', 'it', 'and', 'they', 'choose', 'this', '.', 'Beth', 'was', 'a', 'very', 'accurately', 'drawn', 'character', 'and', 'in', 'the', 'scene', 'where', 'she', 'confronts', 'her', 'mom', 'about', 'the', 'eating', 'disorder', 'you', 'can', 'see', 'the', 'pain', 'inside', 'her', 'and', 'hear', 'it', 'in', 'her', 'voice', 'and', 'you', 'know', 'how', 'deep', 'the', 'pain', 'is', 'that', 'she', 'is', 'feeling', '.', 'I', 'also', 'think', 'one', 'of', 'the', 'best', 'lines', 'in', 'the', 'movie', 'is', 'where', 'Beth', 'yells', 'the', 'words', ',', '\"', 'It', \"'s\", 'not', 'about', 'you', '.', '\"', 'to', 'her', 'mother', '.', 'Those', 'words', 'were', 'so', 'true', 'and', 'added', 'so', 'much', 'to', 'that', 'scene', 'in', 'the', 'movie', '.', 'I', 'think', 'that', 'that', 'scene', 'was', 'definitely', 'the', 'most', 'important', 'scene', 'in', 'that', 'movie', '.'], 'label': 'pos'}\n"]}]},{"cell_type":"code","source":["import random\n","\n","train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n","print(f'Number of training examples: {len(train_data)}')\n","print(f'Number of validation examples: {len(valid_data)}')\n","print(f'Number of testing examples: {len(test_data)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RnxEJ0RB3-J","executionInfo":{"status":"ok","timestamp":1644286150755,"user_tz":480,"elapsed":19,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}},"outputId":"39ab5161-6196-4611-bd2b-cf621b6d5213"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training examples: 17500\n","Number of validation examples: 7500\n","Number of testing examples: 25000\n"]}]},{"cell_type":"code","source":["MAX_VOCAB_SIZE = 25_000\n","\n","TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n","LABEL.build_vocab(train_data)\n","print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n","print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n","print(TEXT.vocab.freqs.most_common(20))\n","print(TEXT.vocab.itos[:10])\n","print(LABEL.vocab.stoi)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#device = torch.device('cpu')\n","# Do not use BucketIterator in your implementation because you are required to implement the padding and masking yourself.\n","#train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=1, device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtSufWSGB_bw","executionInfo":{"status":"ok","timestamp":1644286153159,"user_tz":480,"elapsed":2420,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}},"outputId":"b63a7ce4-d479-4005-aed2-1986a08841dd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique tokens in TEXT vocabulary: 25002\n","Unique tokens in LABEL vocabulary: 2\n","[('the', 202525), (',', 193092), ('.', 165949), ('and', 109557), ('a', 108931), ('of', 100881), ('to', 93484), ('is', 76238), ('in', 61560), ('I', 54174), ('it', 53506), ('that', 49084), ('\"', 44420), (\"'s\", 43297), ('this', 42094), ('-', 37134), ('/><br', 35549), ('was', 35248), ('as', 30532), ('with', 30005)]\n","['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n","defaultdict(None, {'neg': 0, 'pos': 1})\n"]}]},{"cell_type":"code","source":["#split and pad section\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","training_data = train_data\n","#looks like thing is tensored so can use pad sequences\n","temp = (vars(training_data.examples[0])['text'])\n","#print (temp)\n","train_labels = []\n","train_tensors = []\n","train_lens = []\n","max_len = 0\n","\n","#for i in range (0, len(train_data)):\n","#  example = vars(train_data.examples[i])\n","#  if len(example['text']) > max_len:\n","#    max_len = len(example['text']) \n","\n","#print (max_len)\n","vocab = TEXT.vocab.itos\n","for i in range (0, len(train_data)):\n","  example = vars(training_data.examples[i])\n","  temp = []\n","  for j in (example['text']):\n","    temp.append(TEXT.vocab.stoi[j])\n","  #convert to tensor\n","  temp = torch.tensor(temp, dtype = int, device = device) \n","  train_labels.append(example['label'])\n","  train_tensors.append(temp)\n","  train_lens.append(len(temp))\n","#print (len(train_lens))\n","#print (train_lens)\n","\n","valid_labels = []\n","valid_tensors = []\n","valid_lens = []\n","# validation data\n","for i in range (0, len(valid_data)):\n","  example = vars(valid_data.examples[i])\n","  temp = []\n","  for j in (example['text']):\n","    temp.append(TEXT.vocab.stoi[j])\n","  #convert to tensor\n","  temp = torch.tensor(temp, dtype = int, device = device)\n","  valid_labels.append(example['label'])\n","  valid_tensors.append(temp)\n","  valid_lens.append(len(temp))\n","\n","\n","test_labels = []\n","test_tensors = []\n","test_lens = []\n","# validation data\n","for i in range (0, len(test_data)):\n","  example = vars(test_data.examples[i])\n","  temp = []\n","  for j in (example['text']):\n","    temp.append(TEXT.vocab.stoi[j])\n","  #convert to tensor\n","  temp = torch.tensor(temp, dtype = int, device = device)\n","  test_labels.append(example['label'])\n","  test_tensors.append(temp)\n","  test_lens.append(len(temp))"],"metadata":{"id":"S6Wwt-CQzd_T","executionInfo":{"status":"ok","timestamp":1644286161505,"user_tz":480,"elapsed":8354,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class Dataset(torch.utils.data.Dataset):\n","  'Characterizes a dataset for PyTorch'\n","  def __init__(self, list_IDs, labels, seq_lens):\n","        'Initialization'\n","        self.labels = labels\n","        self.list_IDs = list_IDs\n","        self.seq_lens = seq_lens\n","\n","  def __len__(self):\n","        'Denotes the total number of samples'\n","        return len(self.list_IDs)\n","\n","  def __getitem__(self, index):\n","        'Generates one sample of data'\n","        # Select sample\n","        ID = self.list_IDs[index]\n","\n","        # Load data and get label\n","        X =  ID\n","        if self.labels[index] == 'neg':\n","          y = torch.tensor(0, dtype = float, device = device)\n","        else:\n","          y = torch.tensor(1, dtype = float, device = device)\n","        #print (y)\n","        len = self.seq_lens[index]\n","        return X, y, len\n"],"metadata":{"id":"3TIAe99H6hCQ","executionInfo":{"status":"ok","timestamp":1644286161507,"user_tz":480,"elapsed":15,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 128\n","#pad sequence\n","#print (train_tensors)\n","pad_val = TEXT.vocab.stoi[\"<pad>\"]\n","print (pad_val)\n","padded = pad_sequence(train_tensors, batch_first = True, padding_value= pad_val)\n","print (len(padded[0]))\n","train_set = Dataset(padded, train_labels, train_lens)\n","#for i in range (0, 2):#len(train_data)):\n","  #vars(training_data.examples[i])['text'] = train_tensors[i]\n","  #if vars(training_data.examples[i])['label'] =='neg':\n","    #vars(training_data.examples[i])['label'] = 0\n","  #else:\n","    #vars(training_data.examples[i])['label'] = 1\n","\n","  #print (train_tensors[i])\n","#print ((TEXT.vocab.freqs.most_common()))\n","\n","train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE)\n","#print (train_tensors[0])\n","train_features= (iter (train_dataloader))\n","print (vars(train_features))\n","\n","#pad sequence\n","padded = pad_sequence(valid_tensors, batch_first = True)\n","#print (padded)\n","valid_set = Dataset(padded, valid_labels, valid_lens)\n","#\n","valid_dataloader = DataLoader(valid_set, batch_size = BATCH_SIZE)\n","#print (train_tensors[0])\n","valid_features= (iter (valid_dataloader))\n","print (vars(valid_features))\n","\n","padded = pad_sequence(test_tensors, batch_first = True)\n","#print (padded)\n","test_set = Dataset(padded, test_labels, test_lens)\n","#\n","test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE)\n","#print (train_tensors[0])\n","test_features= (iter (test_dataloader))\n","print (vars(test_features))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djsHxYlM9fcG","executionInfo":{"status":"ok","timestamp":1644286163324,"user_tz":480,"elapsed":1832,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}},"outputId":"3055ed71-5bbb-4b07-996c-aa773bc7bd07"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","1989\n","{'_dataset': <__main__.Dataset object at 0x7febbcddc1d0>, '_dataset_kind': 0, '_IterableDataset_len_called': None, '_auto_collation': True, '_drop_last': False, '_index_sampler': <torch.utils.data.sampler.BatchSampler object at 0x7febbcd74cd0>, '_num_workers': 0, '_prefetch_factor': 2, '_pin_memory': False, '_timeout': 0, '_collate_fn': <function default_collate at 0x7febc50814d0>, '_sampler_iter': <generator object BatchSampler.__iter__ at 0x7feb8e4e56d0>, '_base_seed': 3532910284440527571, '_persistent_workers': False, '_num_yielded': 0, '_profile_name': 'enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__', '_dataset_fetcher': <torch.utils.data._utils.fetch._MapDatasetFetcher object at 0x7febbcd74e90>}\n","{'_dataset': <__main__.Dataset object at 0x7febc4c6d090>, '_dataset_kind': 0, '_IterableDataset_len_called': None, '_auto_collation': True, '_drop_last': False, '_index_sampler': <torch.utils.data.sampler.BatchSampler object at 0x7febc4f52e50>, '_num_workers': 0, '_prefetch_factor': 2, '_pin_memory': False, '_timeout': 0, '_collate_fn': <function default_collate at 0x7febc50814d0>, '_sampler_iter': <generator object BatchSampler.__iter__ at 0x7feb8e4e5f50>, '_base_seed': 2252509165406510133, '_persistent_workers': False, '_num_yielded': 0, '_profile_name': 'enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__', '_dataset_fetcher': <torch.utils.data._utils.fetch._MapDatasetFetcher object at 0x7feb99277e90>}\n","{'_dataset': <__main__.Dataset object at 0x7febbce01f50>, '_dataset_kind': 0, '_IterableDataset_len_called': None, '_auto_collation': True, '_drop_last': False, '_index_sampler': <torch.utils.data.sampler.BatchSampler object at 0x7febbce01710>, '_num_workers': 0, '_prefetch_factor': 2, '_pin_memory': False, '_timeout': 0, '_collate_fn': <function default_collate at 0x7febc50814d0>, '_sampler_iter': <generator object BatchSampler.__iter__ at 0x7feb8e4e5e50>, '_base_seed': 8074651545468362100, '_persistent_workers': False, '_num_yielded': 0, '_profile_name': 'enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__', '_dataset_fetcher': <torch.utils.data._utils.fetch._MapDatasetFetcher object at 0x7febbce01150>}\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","class LR(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, output_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx= 1)\n","        self.fc = nn.Linear(embedding_dim, output_dim)\n","    def forward(self, text, seq_lens=None):\n","        embedded = self.embedding(text).sum(1)\n","        return self.fc(embedded)"],"metadata":{"id":"nI_gFLUXCEdY","executionInfo":{"status":"ok","timestamp":1644286163325,"user_tz":480,"elapsed":15,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["\n","#seq_lengths = LongTensor(list(map(len, vectorized_seqs))) this line needs to run in the data structure\n","#\n","#\n","\n","#implementation with the lstm and pack pads\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","class LSTM(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, output_dim, device):\n","        super().__init__()\n","        self.device = device\n","        self.embedding = nn.Embedding(input_dim, embedding_dim,padding_idx=1)\n","        self.lstm = nn.LSTM(embedding_dim, embedding_dim, batch_first=True)\n","        self.fc = nn.Linear(embedding_dim, output_dim)\n","    def forward(self, text, seq_lengths):\n","        embedded = self.embedding(text) #.squeeze().sum(1)\n","        #we need the lengths of all the strings before hand possibly that or we need an identifier for packed stuffs\n","        print (embedded[1])\n","        print (embedded.shape)\n","        print (seq_lengths.shape)\n","        pack = pack_padded_sequence(embedded, seq_lengths, batch_first=True, enforce_sorted=False)\n","        lstm, (ht, ct) = self.lstm(pack) \n","        unpack, input_sizes = pad_packed_sequence(lstm, batch_first=True)\n","        unpack = torch.div(unpack.sum(1), seq_lengths.to(self.device).unsqueeze(1))\n","        return self.fc(unpack)\n"],"metadata":{"id":"hyAx5H3o_Gsb","executionInfo":{"status":"ok","timestamp":1644286163325,"user_tz":480,"elapsed":11,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 64\n","OUTPUT_DIM = 1\n","lr = 0.1 # 1e-3\n","#model = LR(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM)\n","model =LSTM(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, device)"],"metadata":{"id":"-lZ2obDVDmEl","executionInfo":{"status":"ok","timestamp":1644286163326,"user_tz":480,"elapsed":12,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"id":"eJ6_rLRuK2l7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644286163326,"user_tz":480,"elapsed":11,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}},"outputId":"b0f6c8a2-6868-4e61-bf6c-7c746edbb455"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 1,633,473 trainable parameters\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","optimizer = optim.SGD(model.parameters(), lr=lr)"],"metadata":{"id":"IbufnJzvLAlf","executionInfo":{"status":"ok","timestamp":1644286163548,"user_tz":480,"elapsed":231,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["criterion = nn.BCEWithLogitsLoss()"],"metadata":{"id":"I1fHORT8LBOK","executionInfo":{"status":"ok","timestamp":1644286163549,"user_tz":480,"elapsed":12,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"id":"z3gdBHHULC7y","executionInfo":{"status":"ok","timestamp":1644286163549,"user_tz":480,"elapsed":12,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"],"metadata":{"id":"KF2EdETnLEwt","executionInfo":{"status":"ok","timestamp":1644286163550,"user_tz":480,"elapsed":13,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for instance in tqdm(iterator, desc=\"Training...\", total=len(iterator)):\n","        \n","        optimizer.zero_grad()\n","        #not fine \n","        #print (instance[1])  \n","        #print (instance[0].reshape(203, 2))\n","        #temp = (instance[0][0], instance[0][1])\n","        temp = torch.unbind(instance[0])\n","        #print (temp)\n","        reshaped = torch.stack(temp , dim = 1) #(instance[0][0], instance[0][1])\n","        #print (instance[0])\n","        predictions = model(instance[0], instance[2])\n","        #print (instance[0])\n","        #print (len(instance[0]))\n","        #not fine\n","        loss = criterion(predictions, instance[1].float().unsqueeze(1))\n","        #not fine\n","        acc = binary_accuracy(predictions, instance[1].float().unsqueeze(1))\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"2o9l76H5LGm9","executionInfo":{"status":"ok","timestamp":1644286163550,"user_tz":480,"elapsed":13,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for instance in iterator:\n","            #changed this to new format\n","            temp = torch.unbind(instance[0])\n","           #print (temp)\n","            reshaped = torch.stack(temp , dim = 1)\n","            predictions = model(instance[0], instance[2])\n","            \n","            loss = criterion(predictions, instance[1].float().unsqueeze(1))\n","            \n","            acc = binary_accuracy(predictions, instance[1].float().unsqueeze(1))\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"id":"bBwRhOrzLKSH","executionInfo":{"status":"ok","timestamp":1644286163551,"user_tz":480,"elapsed":13,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"FOHkN5P5LMtl","executionInfo":{"status":"ok","timestamp":1644286163551,"user_tz":480,"elapsed":14,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["N_EPOCHS = 5\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    #print (train_dataloader)\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"metadata":{"id":"63EPftxxLOxH","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1644286369149,"user_tz":480,"elapsed":205611,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}},"outputId":"b6d52b07-0ab2-4d17-a159-9bb540aca87a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["\rTraining...:   0%|          | 0/137 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[ 1.0603, -0.1789, -1.1871,  ..., -1.7627,  0.4865, -0.2717],\n","        [-1.0277,  0.9664,  1.2639,  ...,  0.8505, -1.3415, -1.3633],\n","        [ 0.7888, -1.2477, -1.7592,  ...,  0.3942,  0.8515,  0.5374],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","       grad_fn=<SelectBackward0>)\n","torch.Size([128, 1989, 64])\n","torch.Size([128])\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining...:   1%|          | 1/137 [00:23<53:06, 23.43s/it]"]},{"output_type":"stream","name":"stdout","text":["tensor([[-0.0936,  0.1063, -2.9441,  ...,  0.1267,  1.8277,  0.6758],\n","        [ 0.2158, -1.5504,  0.3169,  ..., -0.3651, -1.0719,  0.9414],\n","        [ 0.2209, -0.8245, -0.0256,  ..., -0.6476, -1.8021,  2.4911],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","       grad_fn=<SelectBackward0>)\n","torch.Size([128, 1989, 64])\n","torch.Size([128])\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining...:   1%|▏         | 2/137 [00:47<52:59, 23.55s/it]"]},{"output_type":"stream","name":"stdout","text":["tensor([[-0.0936,  0.1063, -2.9441,  ...,  0.1267,  1.8277,  0.6758],\n","        [ 0.5154,  0.2643, -2.1439,  ...,  0.1590, -0.2309, -1.8214],\n","        [ 0.1092, -0.2081, -1.7573,  ..., -1.2861,  0.9599,  0.1989],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","       grad_fn=<SelectBackward0>)\n","torch.Size([128, 1989, 64])\n","torch.Size([128])\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining...:   2%|▏         | 3/137 [01:08<50:01, 22.40s/it]"]},{"output_type":"stream","name":"stdout","text":["tensor([[ 2.7441,  1.1270,  0.0060,  ...,  0.7659, -0.8096, -0.5267],\n","        [-0.5113, -0.5124, -0.6501,  ...,  1.4856, -0.6763,  0.0937],\n","        [ 1.0027,  0.2835, -0.4596,  ...,  2.2802, -1.5437, -2.1139],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","       grad_fn=<SelectBackward0>)\n","torch.Size([128, 1989, 64])\n","torch.Size([128])\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining...:   3%|▎         | 4/137 [01:27<47:26, 21.40s/it]"]},{"output_type":"stream","name":"stdout","text":["tensor([[-1.4759, -0.3410,  0.0238,  ...,  1.3143,  0.1213,  0.0282],\n","        [-0.8659,  0.5026, -0.1108,  ...,  0.0097,  0.9155, -2.2089],\n","        [-0.9036,  0.9467,  0.4456,  ..., -0.9070,  0.2460, -0.3401],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","       grad_fn=<SelectBackward0>)\n","torch.Size([128, 1989, 64])\n","torch.Size([128])\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining...:   4%|▎         | 5/137 [01:59<54:47, 24.90s/it]"]},{"output_type":"stream","name":"stdout","text":["tensor([[-0.0937,  0.1063, -2.9441,  ...,  0.1267,  1.8277,  0.6758],\n","        [-0.8840,  0.7559, -0.3052,  ..., -0.6270,  0.0283,  1.1135],\n","        [ 0.5409, -1.2138,  0.6935,  ..., -0.5647,  0.9990,  0.7565],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","       grad_fn=<SelectBackward0>)\n","torch.Size([128, 1989, 64])\n","torch.Size([128])\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining...:   4%|▍         | 6/137 [02:27<56:47, 26.01s/it]"]},{"output_type":"stream","name":"stdout","text":["tensor([[-1.0154, -1.3935,  0.5388,  ..., -0.6406,  0.4578,  1.6145],\n","        [ 1.3442, -1.0937, -0.7099,  ...,  0.4685, -0.5173, -1.0919],\n","        [-0.3443, -0.5664,  2.1890,  ...,  1.0872,  1.7377,  0.3472],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","       grad_fn=<SelectBackward0>)\n","torch.Size([128, 1989, 64])\n","torch.Size([128])\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining...:   5%|▌         | 7/137 [02:57<59:26, 27.44s/it]"]},{"output_type":"stream","name":"stdout","text":["tensor([[-0.0937,  0.1063, -2.9441,  ...,  0.1267,  1.8277,  0.6758],\n","        [-0.7625,  1.2473, -1.8907,  ...,  0.0493, -1.8683,  1.8088],\n","        [-0.4573, -0.8678, -0.7842,  ...,  0.0071, -0.1536,  1.1330],\n","        ...,\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","       grad_fn=<SelectBackward0>)\n","torch.Size([128, 1989, 64])\n","torch.Size([128])\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining...:   5%|▌         | 7/137 [03:25<1:03:34, 29.34s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-f0dd39ce82bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-8e29f1a822f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load('tut1-model.pt'))\n","\n","valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n","\n","print(f'Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')"],"metadata":{"id":"PL6fXLc4ltB0","executionInfo":{"status":"aborted","timestamp":1644286369146,"user_tz":480,"elapsed":208,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('tut1-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"metadata":{"id":"s2vQBjeTLTTv","executionInfo":{"status":"aborted","timestamp":1644286369147,"user_tz":480,"elapsed":209,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#confusion matrix"],"metadata":{"id":"cFuPJYs7maSH","executionInfo":{"status":"aborted","timestamp":1644286369148,"user_tz":480,"elapsed":210,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test of model correctness\n","max_n_test_instances = 5\n","i = 1\n","for instance in valid_dataloader:\n","  score = model(instance[0], instance[1])\n","  print(score)\n","  if i >= max_n_test_instances:\n","    break\n","  else:\n","    i += 1\n"],"metadata":{"id":"Ev4idwpONzs9","executionInfo":{"status":"aborted","timestamp":1644286369148,"user_tz":480,"elapsed":210,"user":{"displayName":"Karl Munson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15888825359313586957"}}},"execution_count":null,"outputs":[]}]}